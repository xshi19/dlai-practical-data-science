{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize models using Automatic Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "When training ML models, hyperparameter tuning is a step to get best quality out of the training model. In this lab you will apply a random algorithm of the Automated Hyperparameter Tuning to train a BERT-based natural language processing (NLP) classifier. The model is analyzing customer feedback and classifying the messages into positive (1), neutral (0) and negative (-1) sentiment.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [1. Configure dataset and Hyperparameter Tuning Job (HTP)](#c3w1-1.)\n",
    "  - [1.1. Configure dataset](#c3w1-1.1.)\n",
    "  - [1.2. Configure Hyperparameter Tuning Job](#c3w1-1.2.)\n",
    "  - [1.3. Setup evaluation metrics](#c3w1-1.3.)\n",
    "- [2. Run tuning job](#c3w1-2.)\n",
    "  - [2.1. Setup the RoBERTa and PyTorch script to run on SageMaker](#c3w1-2.1.)\n",
    "  - [2.2. Launch the Hyperparameter Tuning Job](#c3w1-2.2.)\n",
    "  - [2.3. Check Tuning Job status](#c3w1-2.3.)\n",
    "- [3. Evaluate the results](#c3w1-3.)\n",
    "  - [3.1. Show the best candidate](#c3w1-3.1.)\n",
    "  - [3.2. Evaluate the best candidate](#c3w1-3.2.)\n",
    "  - [3.3. Inspect the processed output data](#c3w1-3.3.)\n",
    "\n",
    "Amazon SageMaker supports Automated Hyperparameter Tuning. It runs multiple training jobs on the training dataset using the hyperparameter ranges specified by user. Then it chooses the combination of the hyperparameters that leads to the best model candidate. The choice is made based on the objective metrics, e.g. maximization of the validation accuracy. \n",
    "\n",
    "For the choice of hyperparameters combinations, SageMaker supports two different types of tuning strategies: random and bayesian. This capability can be further extended by provising an implementation of a custom tuning strategy as a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hpt.png\" width=\"70%\" align=\"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following three steps:\n",
    "\n",
    "<img src=\"images/sagemaker_hpt.png\" width=\"50%\" align=\"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install and import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.'></a>\n",
    "# 1. Configure dataset and Hyperparameter Tuning Job (HTP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.1.'></a>\n",
    "### 1.1. Configure dataset\n",
    "\n",
    "Let's copy data to S3 bucket. Setup the paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data_s3_uri = 's3://{}/transformed/data/sentiment-train/'.format(bucket)\n",
    "processed_validation_data_s3_uri = 's3://{}/transformed/data/sentiment-validation/'.format(bucket)\n",
    "processed_test_data_s3_uri = 's3://{}/transformed/data/sentiment-test/'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data to S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive ./data/sentiment-train $processed_train_data_s3_uri\n",
    "!aws s3 cp --recursive ./data/sentiment-validation $processed_validation_data_s3_uri\n",
    "!aws s3 cp --recursive ./data/sentiment-test $processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the existence of those files in the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls --recursive $processed_train_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls --recursive $processed_validation_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls --recursive $processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to setup the input data channels, wrapping the S3 locations in a `TrainingInput` object to use with the SageMaker Tuning Job. This can be organized as a dictionary\n",
    "\n",
    "```python\n",
    "data_channels = {\n",
    "    'train': ..., # training data\n",
    "    'validation': ... # validation data\n",
    "}\n",
    "```\n",
    "\n",
    "where training and validation data are the Amazon SageMaker channels for S3 input data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-1'></a>\n",
    "### Exercise 1\n",
    "\n",
    "Create a train data channel.\n",
    "\n",
    "**Instructions**: Pass the S3 input path for training data into the `sagemaker.inputs.TrainingInput` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train_data = sagemaker.inputs.TrainingInput(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    s3_data=None # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-2'></a>\n",
    "### Exercise 2\n",
    "\n",
    "Create a validation data channel.\n",
    "\n",
    "**Instructions**: Pass the S3 input path for validation data into the `sagemaker.inputs.TrainingInput` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_validation_data = sagemaker.inputs.TrainingInput(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    s3_data=None # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-3'></a>\n",
    "### Exercise 3\n",
    "\n",
    "Organize the defined above train and validation data channels as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    'train': None, # Replace None\n",
    "    'validation': None # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_test_data = TrainingInput(s3_data=processed_test_data_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.2.'></a>\n",
    "### 1.2. Configure Hyperparameter Tuning Job\n",
    "\n",
    "Model hyperparameters need to be set prior to starting the model training as they control the process of learning. Some of the hyperparameters you will set up as static - they will not be explored during the tuning job. For the non-static hyperparametrs you will set the range of possible values to be explored.\n",
    "\n",
    "First, configure static hyperparameters including the instance type, instance count, maximum sequence length etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length=128 # maximum number of input tokens passed to BERT model\n",
    "freeze_bert_layer=False # specifies the depth of training within the network\n",
    "epochs=3\n",
    "train_steps_per_epoch=50\n",
    "validation_batch_size=64\n",
    "validation_steps_per_epoch=50\n",
    "seed=42\n",
    "\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.c5.9xlarge'\n",
    "train_volume_size=256\n",
    "input_mode='File'\n",
    "run_validation=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them will be passed into the PyTorch estimator and tuner in the hyperparameters argument. Let's setup the dictionary for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'freeze_bert_layer': freeze_bert_layer,\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'epochs': epochs,\n",
    "    'train_steps_per_epoch': train_steps_per_epoch,\n",
    "    'validation_batch_size': validation_batch_size,\n",
    "    'validation_steps_per_epoch': validation_steps_per_epoch,\n",
    "    'seed': seed,\n",
    "    'run_validation': run_validation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure hyperparameter ranges to explore in the Tuning Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter\n",
    "from sagemaker.tuner import ContinuousParameter\n",
    "from sagemaker.tuner import CategoricalParameter\n",
    "                                                \n",
    "hyperparameter_ranges = {\n",
    "    'learning_rate': ContinuousParameter(0.00001, 0.00005, scaling_type='Linear'), # specifying continuous variable type, the tuning job will explore the range of values\n",
    "    'train_batch_size': CategoricalParameter([128, 256]), # specifying categorical variable type, the tuning job will explore only listed values\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-1.3.'></a>\n",
    "### 1.3. Setup evaluation metrics\n",
    "\n",
    "Choose loss and accuracy as the evaluation metrics. The regular expressions `Regex` will capture the values of metrics that the algorithm will emit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, these sample log lines...\n",
    "```\n",
    "[step: 100] val_loss: 0.76 - val_acc: 70.92%\n",
    "```\n",
    "\n",
    "...will produce the following metrics in CloudWatch:\n",
    "\n",
    "`validation:loss` =  0.76\n",
    "\n",
    "`validation:accuracy` = 70.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cloudwatch_validation_metrics.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Tuning Job you will be maximizing validation accuracy as the objective metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.'></a>\n",
    "# 2. Run Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.1.'></a>\n",
    "### 2.1. Setup the RoBERTa and PyTorch script to run on SageMaker\n",
    "\n",
    "Prepare the PyTorch model to run as a SageMaker Training Job. The estimator takes into the entry point a separate Python file, which will be called during the training. You can open and review this file [src/train.py](src/train.py).\n",
    "\n",
    "For more information on the `PyTorchEstimator`, see the documentation here: https://sagemaker.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch as PyTorchEstimator\n",
    "\n",
    "estimator = PyTorchEstimator(\n",
    "    entry_point='train.py',\n",
    "    source_dir='src',\n",
    "    role=role,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    volume_size=train_volume_size,\n",
    "    py_version='py3',\n",
    "    framework_version='1.6.0',\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    input_mode=input_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.2.'></a>\n",
    "### 2.2. Launch the Hyperparameter Tuning Job\n",
    "\n",
    "A hyperparameter tuning job runs a series of training jobs that each test a combination of hyperparameters for a given objective metric (i.e. `train:accuracy`). In this lab, you will use a `Random` search strategy to determine the combinations of hyperparameters - within the specific ranges - to use for each training job within the tuning job.  For more information on hyperparameter tuning search strategies, please see the following documentation:  https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html\n",
    "\n",
    "When the tuning job completes, we can select the hyperparameters used by the best-performing training job relative to the objective metric (i.e. `train:accuracy`). \n",
    "\n",
    "The `max_jobs` parameter is a stop criteria that limits the number of overall training jobs (and therefore hyperparameter combinations) to run within the tuning job.\n",
    "\n",
    "The `max_parallel_jobs` parameter limits the number of training jobs (and therefore hyperparameter combinations) to run in parallel within the tuning job.  This parameter is often used in combination with the `Bayesian` search strategy when we want to test a smaller set of training jobs (less than the `max_jobs`), learn from the smaller set of training jobs, then apply Bayesian methods to determine the next set of hyperparameters used by the next set of training jobs.  Bayesian methods can improve hyperparameter-tuning performance in some cases.\n",
    "\n",
    "\n",
    "The `early_stopping_type` parameter is used by SageMaker hyper-parameter tuning jobs to automatically stop a training job if the job is not improving the objective metrics (i.e. `train:accuracy`) relative to previous training jobs within the tuning job.  For more information on early stopping, please see the following documentation:  https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-4'></a>\n",
    "### Exercise 4\n",
    "\n",
    "Setup the Hyperparameter Tuner.\n",
    "\n",
    "**Instructions**: Use the function `HyperparameterTuner` passing the variables defined above. Please use tuning strategy `'Random'`.\n",
    "\n",
    "```python\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=..., # estimator\n",
    "    hyperparameter_ranges=..., # hyperparameter ranges\n",
    "    metric_definitions=..., # definition metric\n",
    "    strategy='...', # tuning strategy\n",
    "    objective_type='Maximize',\n",
    "    objective_metric_name='train:accuracy',\n",
    "    max_jobs=2, # maximum number of jobs to run\n",
    "    max_parallel_jobs=2, # maximum number of jobs to run in parallel\n",
    "    early_stopping_type='Auto' # early stopping criteria\n",
    ")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    estimator=None, # Replace None\n",
    "    hyperparameter_ranges=None, # Replace None\n",
    "    metric_definitions=None, # Replace None\n",
    "    strategy=None, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    objective_type='Maximize',\n",
    "    objective_metric_name='validation:accuracy',\n",
    "    max_jobs=2, # maximum number of jobs to run\n",
    "    max_parallel_jobs=2, # maximum number of jobs to run in parallel\n",
    "    early_stopping_type='Auto' # early stopping criteria\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-5'></a>\n",
    "### Exercise 5\n",
    "\n",
    "Launch the SageMaker Hyper-Parameter Tuning (HPT) Job.\n",
    "\n",
    "**Instructions**: Use the `tuner.fit` function passing the configured train and validation inputs (data channels).\n",
    "\n",
    "```python\n",
    "tuner.fit(\n",
    "    inputs=..., # train and validation input\n",
    "    include_cls_metadata=False, # to be set as false if the algorithm cannot handle unknown hyperparameters\n",
    "    wait=False # do not wait for the job to complete before continuing\n",
    ")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    inputs=None, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    include_cls_metadata=False,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-2.3.'></a>\n",
    "### 2.3. Check Tuning Job status\n",
    "You can see the Tuning Job status in the console. Let's get the Tuning Job name first to construct the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuning_job_name = tuner.latest_tuning_job.job_name\n",
    "print(tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the status of the Tuning Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "    \n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/{}\">Hyper-Parameter Tuning Job</a></b>'.format(region, tuning_job_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the Tuning Job to complete.\n",
    "\n",
    "### _This cell will take approximately 20-30 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Wait until the ^^ Tuning Job ^^ completes above_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the SageMaker Hyperparameter Tuning Job are available on the `analytics` of the `tuner object`. `dataframe` function converts the result directly into the dataframe. You can explore the results with the following lines of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(10) # slight delay to allow the analytics to be calculated\n",
    "\n",
    "df_results = tuner.analytics().dataframe()\n",
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.sort_values('FinalObjectiveValue', ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.'></a>\n",
    "# 3. Evaluate the results\n",
    "\n",
    "An important part of developing a model is evaluating the model with test data set that the model has never seen during its training process. These final metrics resulting from this evaluation can be used to compare competing machine learning models. The higher the value of these metrics, the better is the ability of the model to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.1.'></a>\n",
    "### 3.1. Show the best candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-ex-6'></a>\n",
    "### Exercise 6\n",
    "\n",
    "Show the best candidate.\n",
    "\n",
    "**Instructions**: Use the `sort_values` function to sort the results by accuracy which is stored in the column `FinalObjectiveValue`. Put `ascending=0` and `head(1)` for the selection.\n",
    "\n",
    "```python\n",
    "df_results.sort_values(\n",
    "    '...', # column name for sorting\n",
    "    ascending=0).head(1)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.sort_values(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    None, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    ascending=0).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.2.'></a>\n",
    "### 3.2. Evaluate the best candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_candidate_training_job_name = df_results.sort_values('FinalObjectiveValue', ascending=0).iloc[0]['TrainingJobName']\n",
    "print('Best candidate training job name: {}'.format(best_candidate_training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tar_s3_uri = sm.describe_training_job(TrainingJobName=best_candidate_training_job_name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_tar_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processing_instance_type = \"ml.c5.2xlarge\"\n",
    "processing_instance_count = 1\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    max_runtime_in_seconds=7200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload and Configure S3 Path for Raw Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 ./data/sentiment-test/part-algo-1-womens_clothing_ecommerce_reviews.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_data_s3_uri = 's3://{}/data/sentiment-test/'.format(bucket)\n",
    "print(raw_test_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive ./data/sentiment-test/ $raw_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls --recursive $raw_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can review the file [src/evaluate_model_metrics.py](src/evaluate_model_metrics.py) which is used for the model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "processor.run(\n",
    "    code=\"src/evaluate_model_metrics.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(  \n",
    "            input_name=\"model-tar-s3-uri\",                        \n",
    "            source=model_tar_s3_uri,                               \n",
    "            destination=\"/opt/ml/processing/input/model/\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            input_name=\"evaluation-data-s3-uri\",\n",
    "            source=raw_test_data_s3_uri,                                    \n",
    "            destination=\"/opt/ml/processing/input/data/\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(s3_upload_mode=\"EndOfJob\", output_name=\"metrics\", source=\"/opt/ml/processing/output/metrics\"),\n",
    "    ],\n",
    "    arguments=[\"--max-seq-length\", str(max_seq_length)],\n",
    "    logs=True,\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scikit_processing_job_name = processor.jobs[-1].describe()[\"ProcessingJobName\"]\n",
    "print(scikit_processing_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\">Processing Job</a></b>'.format(\n",
    "            region, scikit_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(\n",
    "            region, scikit_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Processing Job Has Completed</b>'.format(\n",
    "            bucket, scikit_processing_job_name, region\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n",
    "    processing_job_name=scikit_processing_job_name, sagemaker_session=sess\n",
    ")\n",
    "\n",
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "pprint(processing_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the processing job to complete.\n",
    "\n",
    "### _This cell will take approximately 5-10 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "running_processor.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w1-3.3.'></a>\n",
    "### 3.3. Inspect the processed output data\n",
    "\n",
    "Take a look at a few rows of the transformed dataset to make sure the processing was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "output_config = processing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"metrics\":\n",
    "        processed_metrics_s3_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "print(processed_metrics_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $processed_metrics_s3_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "metrics_json = sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n",
    "    processed_metrics_s3_uri\n",
    "))\n",
    "\n",
    "print('Test accuracy: {}'.format(json.loads(metrics_json)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $processed_metrics_s3_uri/confusion_matrix.png ./generated/\n",
    "\n",
    "import time\n",
    "time.sleep(10) # Slight delay for our notebook to recognize the newly-downloaded file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the confusion matrix generated during model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<img src='./generated/confusion_matrix.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the notebook into S3 bucket for grading purposes.\n",
    "\n",
    "**Note:** you may need to click on \"Save\" button before the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./C3_W1_Assignment.ipynb s3://$bucket/C3_W1_Assignment_Learner.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Graders are not implemented at this stage of testing - please do not submit the assignment for grading_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
