{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B testing, traffic shifting and autoscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)\n",
    "cw = boto3.Session().client(service_name='cloudwatch', region_name=region)\n",
    "autoscale = boto3.Session().client(service_name=\"application-autoscaling\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canary Rollouts and A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canary rollouts are used to release new models safely to only a small subset of users such as 5%. They are useful if you want to test in live production without affecting the entire user base. Since the majority of traffic goes to the existing model, the cluster size of the canary model can be relatively small since it’s only receiving 5% traffic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `deploy()`, we can create an `Endpoint Configuration` with multiple variants for canary rollouts and A/B testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom `SentimentPredictor` that encapsulates a JSONLines serializer and deserializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "class SentimentPredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, \n",
    "                         sagemaker_session=sagemaker_session, \n",
    "                         serializer=JSONLinesSerializer(),\n",
    "                         deserializer=JSONLinesDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_a/model.tar.gz'\n",
    "model_b_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_b/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_a = '{}-{}'.format('a', timestamp)\n",
    "\n",
    "model_a = PyTorchModel(name=model_name_a,\n",
    "                       model_data=model_a_s3_uri,\n",
    "                       predictor_cls=SentimentPredictor,\n",
    "                       entry_point='inference.py',\n",
    "                       source_dir='src',\n",
    "                       framework_version='1.6.0',\n",
    "                       py_version='py3',\n",
    "                       role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_b = '{}-{}'.format('b', timestamp)\n",
    "\n",
    "model_b = PyTorchModel(name=model_name_b,\n",
    "                       model_data=model_b_s3_uri,\n",
    "                       predictor_cls=SentimentPredictor,\n",
    "                       entry_point='inference.py',\n",
    "                       source_dir='src',\n",
    "                       framework_version='1.6.0',\n",
    "                       py_version='py3',\n",
    "                       role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = 'ml.m5.large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"1.6.0\",\n",
    "    py_version='py3',\n",
    "    instance_type=inference_instance_type,\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.create_model(\n",
    "    name=model_name_a, \n",
    "    role=role, \n",
    "    container_defs=sagemaker.container_def(\n",
    "        model_data_url=model_a_s3_uri, \n",
    "        image_uri=inference_image_uri\n",
    "    )    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.create_model(\n",
    "    name=model_name_b,\n",
    "    role=role, \n",
    "    container_defs=sagemaker.container_def(\n",
    "        model_data_url=model_b_s3_uri, \n",
    "        image_uri=inference_image_uri\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import production_variant\n",
    "\n",
    "variantA = production_variant(\n",
    "    model_name=model_name_a,\n",
    "    instance_type=inference_instance_type,\n",
    "    initial_instance_count=1,\n",
    "    variant_name='VariantA',\n",
    "    initial_weight=50,\n",
    ")\n",
    "print(variantA)\n",
    "\n",
    "variantB = production_variant(\n",
    "    model_name=model_name_b,\n",
    "    instance_type=inference_instance_type,\n",
    "    initial_instance_count=1,\n",
    "    variant_name='VariantB',\n",
    "    initial_weight=50,\n",
    ")\n",
    "print(variantB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = '{}-{}'.format('ab', timestamp)\n",
    "\n",
    "endpoint_config = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name, ProductionVariants=[variantA, variantB]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "model_ab_endpoint_name = '{}-{}'.format('ab', timestamp)\n",
    "\n",
    "endpoint_response = sm.create_endpoint(EndpointName=model_ab_endpoint_name, \n",
    "                                       EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "pprint(endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpointConfig/{}\">REST Endpoint Configuration</a></b>'.format(\n",
    "            region, endpoint_config_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, model_ab_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the endpoint to deploy.\n",
    "\n",
    "### _This cell will take approximately 5-10 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Wait until the ^^ Endpoint ^^ is deployed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "Here, we will pass sample strings of text to the endpoint in order to see the sentiment. We give you one example of each, however, feel free to play around and change the strings yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    {\"features\": [\"I love this product!\"]},\n",
    "    {\"features\": [\"OK, but not great.\"]},\n",
    "    {\"features\": [\"This is not the right product.\"]},\n",
    "]\n",
    "\n",
    "predictor = SentimentPredictor(endpoint_name=model_ab_endpoint_name,\n",
    "                               sagemaker_session=sess)\n",
    "\n",
    "predicted_classes = predictor.predict(inputs)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review the REST Endpoint Performance Metrics in a Dataframe\n",
    "\n",
    "Amazon SageMaker emits metrics such as Latency and Invocations (full list of metrics [here](https://alpha-docs-aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html)) for each variant in Amazon CloudWatch. Let’s query CloudWatch to get the InvocationsPerVariant to show how invocations are split across variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_invocation_metrics_for_endpoint_variant(\n",
    "    endpoint_name, namespace_name, metric_name, variant_name, start_time, end_time\n",
    "):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=namespace_name,\n",
    "        MetricName=metric_name,\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[{\"Name\": \"EndpointName\", \"Value\": endpoint_name}, {\"Name\": \"VariantName\", \"Value\": variant_name}],\n",
    "    )\n",
    "\n",
    "    if metrics[\"Datapoints\"]:\n",
    "        return (\n",
    "            pd.DataFrame(metrics[\"Datapoints\"])\n",
    "            .sort_values(\"Timestamp\")\n",
    "            .set_index(\"Timestamp\")\n",
    "            .drop(\"Unit\", axis=1)\n",
    "            .rename(columns={\"Sum\": variant_name})\n",
    "        )\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def plot_endpoint_metrics_for_variants(endpoint_name, namespace_name, metric_name, start_time=None):\n",
    "    try:\n",
    "        start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "        end_time = datetime.now()\n",
    "\n",
    "        metrics_variantA = get_invocation_metrics_for_endpoint_variant(\n",
    "            endpoint_name=model_ab_endpoint_name,\n",
    "            namespace_name=namespace_name,\n",
    "            metric_name=metric_name,\n",
    "            variant_name=variantA[\"VariantName\"],\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "        )\n",
    "\n",
    "        metrics_variantB = get_invocation_metrics_for_endpoint_variant(\n",
    "            endpoint_name=model_ab_endpoint_name,\n",
    "            namespace_name=namespace_name,\n",
    "            metric_name=metric_name,\n",
    "            variant_name=variantB[\"VariantName\"],\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "        )\n",
    "\n",
    "        metrics_variants = metrics_variantA.join(metrics_variantB, how=\"outer\")\n",
    "        metrics_variants.plot()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some predictions and view the invocation metrics.\n",
    "\n",
    "_This will take 1-2 minutes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, model_ab_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the Metrics for Each Variant\n",
    "If you see `Metrics not yet available`, please be patient as metrics may take a few mins to appear in CloudWatch.\n",
    "\n",
    "Also, make sure the predictions ran successfully above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# time.sleep(20)\n",
    "# plot_endpoint_metrics_for_variants(\n",
    "#     endpoint_name=model_ab_endpoint_name, namespace_name=\"/aws/sagemaker/Endpoints\", metric_name=\"CPUUtilization\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# time.sleep(5)\n",
    "# plot_endpoint_metrics_for_variants(\n",
    "#     endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"Invocations\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# time.sleep(5)\n",
    "# plot_endpoint_metrics_for_variants(\n",
    "#     endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"InvocationsPerInstance\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# time.sleep(5)\n",
    "# plot_endpoint_metrics_for_variants(\n",
    "#     endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"ModelLatency\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shift All Traffic to Variant B\n",
    "_**No downtime** occurs during this traffic-shift activity._\n",
    "\n",
    "This may take a few minutes.  Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_endpoint_config = [\n",
    "    {\n",
    "        \"VariantName\": variantA[\"VariantName\"],\n",
    "        \"DesiredWeight\": 0,\n",
    "    },\n",
    "    {\n",
    "        \"VariantName\": variantB[\"VariantName\"],\n",
    "        \"DesiredWeight\": 100,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=model_ab_endpoint_name, DesiredWeightsAndCapacities=updated_endpoint_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait for the ^^ Endpoint Update ^^ to Complete Above.\n",
    "\n",
    "_There is no down-time while the update is applying._ \n",
    "\n",
    "This may take a few minutes.  Please be patient.\n",
    "\n",
    "![](img/autoscale-endpoint-updating.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, model_ab_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some predictions and view the invocation metrics.\n",
    "\n",
    "_This will take 1-2 minutes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, model_ab_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "time.sleep(20)\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"/aws/sagemaker/Endpoints\", metric_name=\"CPUUtilization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the Metrics for Each Variant\n",
    "If you see `Metrics not yet available`, please be patient as metrics may take a few mins to appear in CloudWatch.\n",
    "\n",
    "Also, make sure the predictions ran successfully above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "time.sleep(20)\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"/aws/sagemaker/Endpoints\", metric_name=\"CPUUtilization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# time.sleep(5)\n",
    "# plot_endpoint_metrics_for_variants(\n",
    "#     endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"Invocations\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# time.sleep(5)\n",
    "# plot_endpoint_metrics_for_variants(\n",
    "#     endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"InvocationsPerInstance\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# time.sleep(5)\n",
    "# plot_endpoint_metrics_for_variants(\n",
    "#     endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"ModelLatency\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Variant B to Autoscale (but not Variant A since A is no longer taking traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscale.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2,\n",
    "    RoleARN=role,\n",
    "    SuspendedState={\n",
    "        \"DynamicScalingInSuspended\": False,\n",
    "        \"DynamicScalingOutSuspended\": False,\n",
    "        \"ScheduledScalingSuspended\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the target is available\n",
    "autoscale.describe_scalable_targets(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    MaxResults=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscale.put_scaling_policy(\n",
    "    PolicyName=\"bert-reviews-autoscale-policy\",\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"TargetValue\": 2.0,\n",
    "        \"PredefinedMetricSpecification\": {\n",
    "            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\",\n",
    "        },\n",
    "        \"ScaleOutCooldown\": 60,\n",
    "        \"ScaleInCooldown\": 300,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Traffic\n",
    "This may take a few minutes.  Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the autoscaling.\n",
    "\n",
    "![](img/autoscale-instance-count.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, model_ab_endpoint_name)))\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
